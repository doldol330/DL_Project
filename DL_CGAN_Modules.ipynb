{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPaOgLJZHPgnCcsrZdhucKZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/doldol330/DL_Project/blob/main/DL_CGAN_Modules.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0pkk_DvKiRsS"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from musegan.libs.ops import *\n",
        "from musegan.libs.utils import *\n",
        "\n",
        "class PhraseGenerator(object):\n",
        "    def __init__(self, name='PG', output_dim=1, is_bn=True):\n",
        "        self.output_dim = output_dim\n",
        "        self.name = name\n",
        "        self.is_bn = is_bn\n",
        "\n",
        "    def __call__(self, in_tensor, input_track=None, reuse=False):\n",
        "        with tf.variable_scope(self.name, reuse=reuse):\n",
        "            if input_track is not None:\n",
        "                input_track_reshaped = tf.reshape(input_track, [-1, input_track.get_shape()[1], 1])\n",
        "                in_tensor = tf.concat([in_tensor, input_track_reshaped], axis=2)\n",
        "\n",
        "            h0 = tf.reshape(in_tensor, tf.stack([-1, 1, 1, in_tensor.get_shape()[1]]))\n",
        "            h0 = relu(batch_norm(transconv2d(h0, [2, 1], 1024, kernels=[2, 1],\n",
        "                                            strides=[2, 1], name='h1'), self.is_bn))\n",
        "            h1 = relu(batch_norm(transconv2d(h0, [4, 1], self.output_dim,\n",
        "                                            kernels=[3, 1], strides=[1, 1], name='h2'), self.is_bn))\n",
        "            h1 = tf.transpose(tf.squeeze(h1, axis=2), [0, 2, 1])\n",
        "\n",
        "        return h1\n",
        "\n",
        "class BarGenerator(object):\n",
        "    def __init__(self, name='BG', output_dim=1, is_bn=True):\n",
        "        self.output_dim = output_dim\n",
        "        self.name = name\n",
        "        self.is_bn = is_bn\n",
        "\n",
        "    def __call__(self, in_tensor, nowbar=None, input_track=None, reuse=False, type_=0):\n",
        "        with tf.variable_scope(self.name, reuse=reuse):\n",
        "            # 입력 트랙 정보를 포함하여 텐서를 생성\n",
        "            if input_track is not None:\n",
        "                input_track_reshaped = tf.reshape(input_track, [-1, 1, 1, input_track.get_shape()[-1]])\n",
        "                in_tensor = tf.concat([in_tensor, input_track_reshaped], axis=3)\n",
        "\n",
        "        print('KKKKKKKKKKKKKKKKKKKK', type_ )\n",
        "        if type_ is 0:\n",
        "            with tf.variable_scope(self.name, reuse=reuse):\n",
        "\n",
        "                h0 = tf.reshape(in_tensor, tf.stack([-1, 1, 1, in_tensor.get_shape()[1]]))\n",
        "                h0 = relu(batch_norm(transconv2d(h0, [1, 1], 1024, kernels=[1, 1], strides=[1, 1], name='h0'), self.is_bn))\n",
        "\n",
        "                h1 = tf.reshape(h0, [-1, 2, 1, 512])\n",
        "                h1 = concat_prev(h1, nowbar[6] if nowbar else None)\n",
        "                h1 = relu(batch_norm(transconv2d(h1, [4, 1], 512, kernels=[2, 1], strides=[2, 1], name='h1'), self.is_bn))\n",
        "\n",
        "                h2 = concat_prev(h1, nowbar[5] if nowbar else None)\n",
        "                h2 = relu(batch_norm(transconv2d(h2, [8, 1], 256, kernels=[2, 1], strides=[2, 1], name='h2'), self.is_bn))\n",
        "\n",
        "                h3 = concat_prev(h2, nowbar[4] if nowbar else None)\n",
        "                h3 = relu(batch_norm(transconv2d(h3, [16, 1], 256, kernels=[2, 1], strides=[2, 1], name='h3'), self.is_bn))\n",
        "\n",
        "                h4 = concat_prev(h3, nowbar[3] if nowbar else None)\n",
        "                h4 = relu(batch_norm(transconv2d(h4, [32, 1], 128, kernels=[2, 1], strides=[2, 1], name='h4'), self.is_bn))\n",
        "\n",
        "                h5 = concat_prev(h4, nowbar[2] if nowbar else None)\n",
        "                h5 = relu(batch_norm(transconv2d(h5, [96, 1], 128, kernels=[3, 1], strides=[3, 1], name='h5'), self.is_bn))\n",
        "\n",
        "                h6 = concat_prev(h5, nowbar[1] if nowbar else None)\n",
        "                h6 = relu(batch_norm(transconv2d(h6, [96, 7], 64, kernels=[1, 7], strides=[1, 1], name='h6'), self.is_bn))\n",
        "\n",
        "                h7 = concat_prev(h6, nowbar[0] if nowbar else None)\n",
        "                h7 = transconv2d(h7, [96, 84], self.output_dim, kernels=[1, 12], strides=[1, 12], name='h7')\n",
        "\n",
        "            return tf.nn.tanh(h7)\n",
        "\n",
        "        elif type_ is 1:\n",
        "            with tf.variable_scope(self.name, reuse=reuse):\n",
        "\n",
        "                h0 = tf.reshape(in_tensor, tf.stack([-1, 1, 1, in_tensor.get_shape()[1]]))\n",
        "                h0 = relu(batch_norm(transconv2d(h0, [1, 1], 1024, kernels=[1, 1], strides=[1, 1], name='h0'), self.is_bn))\n",
        "\n",
        "                h1 = tf.reshape(h0, [-1, 2, 1, 512])\n",
        "                h1 = concat_prev(h1, nowbar[6] if nowbar else None)\n",
        "                h1 = relu(batch_norm(transconv2d(h1, [6, 1], 512, kernels=[3, 1], strides=[3, 1], name='h1'), self.is_bn))\n",
        "\n",
        "                h2 = concat_prev(h1, nowbar[5] if nowbar else None)\n",
        "                h2 = relu(batch_norm(transconv2d(h2, [12, 1], 256, kernels=[2, 1], strides=[2, 1], name='h2'), self.is_bn))\n",
        "\n",
        "                h3 = concat_prev(h2, nowbar[4] if nowbar else None)\n",
        "                h3 = relu(batch_norm(transconv2d(h3, [24, 1], 256, kernels=[2, 1], strides=[2, 1], name='h3'), self.is_bn))\n",
        "\n",
        "                h4 = concat_prev(h3, nowbar[3] if nowbar else None)\n",
        "                h4 = relu(batch_norm(transconv2d(h4, [48, 1], 128, kernels=[2, 1], strides=[2, 1], name='h4'), self.is_bn))\n",
        "\n",
        "                h5 = concat_prev(h4, nowbar[2] if nowbar else None)\n",
        "                h5 = relu(batch_norm(transconv2d(h5, [96, 1], 128, kernels=[2, 1], strides=[2, 1], name='h5'), self.is_bn))\n",
        "\n",
        "                h6 = concat_prev(h5, nowbar[1] if nowbar else None)\n",
        "                h6 = relu(batch_norm(transconv2d(h6, [96, 7], 64, kernels=[1, 7], strides=[1, 1], name='h6'), self.is_bn))\n",
        "\n",
        "                h7 = concat_prev(h6, nowbar[0] if nowbar else None)\n",
        "                h7 = transconv2d(h7, [96, 84], self.output_dim, kernels=[1, 12], strides=[1, 12], name='h7')\n",
        "\n",
        "            return tf.nn.tanh(h7)\n",
        "\n",
        "        elif type_ is 2:\n",
        "            with tf.variable_scope(self.name, reuse=reuse):\n",
        "\n",
        "                h0 = tf.reshape(in_tensor, tf.stack([-1, 1, 1, in_tensor.get_shape()[1]]))\n",
        "                h0 = relu(batch_norm(transconv2d(h0, [1, 1], 1024, kernels=[1, 1], strides=[1, 1], name='h0'), self.is_bn))\n",
        "\n",
        "                h1 = tf.reshape(h0, [-1, 2, 1, 512])\n",
        "                h1 = concat_prev(h1, nowbar[6] if nowbar else None)\n",
        "                h1 = relu(batch_norm(transconv2d(h1, [12, 1], 512, kernels=[6, 1], strides=[6, 1], name='h1'), self.is_bn))\n",
        "\n",
        "                h2 = concat_prev(h1, nowbar[5] if nowbar else None)\n",
        "                h2 = relu(batch_norm(transconv2d(h2, [24, 1], 256, kernels=[2, 1], strides=[2, 1], name='h2'), self.is_bn))\n",
        "\n",
        "                h3 = concat_prev(h2, nowbar[4] if nowbar else None)\n",
        "                h3 = relu(batch_norm(transconv2d(h3, [48, 1], 256, kernels=[2, 1], strides=[2, 1], name='h3'), self.is_bn))\n",
        "\n",
        "                h4 = concat_prev(h3, nowbar[3] if nowbar else None)\n",
        "                h4 = relu(batch_norm(transconv2d(h4, [96, 1], 128, kernels=[2, 1], strides=[2, 1], name='h4'), self.is_bn))\n",
        "\n",
        "                # h5 = concat_prev(h4, nowbar[2] if nowbar else None)\n",
        "                # h5 = relu(batch_norm(transconv2d(h5, [96, 1], 128, kernels=[2, 1], strides=[2, 1], name='h5'), self.is_bn))\n",
        "\n",
        "                h6 = concat_prev(h4, nowbar[1] if nowbar else None)\n",
        "                h6 = relu(batch_norm(transconv2d(h6, [96, 7], 64, kernels=[1, 7], strides=[1, 1], name='h6'), self.is_bn))\n",
        "\n",
        "                h7 = concat_prev(h6, nowbar[0] if nowbar else None)\n",
        "                h7 = transconv2d(h7, [96, 84], self.output_dim, kernels=[1, 12], strides=[1, 12], name='h7')\n",
        "\n",
        "            return tf.nn.tanh(h7)\n",
        "\n",
        "class BarEncoder(object):\n",
        "    def __init__(self, name='BE', is_bn=True):\n",
        "        self.name = name\n",
        "        self.is_bn = is_bn\n",
        "\n",
        "    def __call__(self, in_tensor, reuse=False):\n",
        "        with tf.variable_scope(self.name, reuse=reuse):\n",
        "            h0 = lrelu(batch_norm(conv2d(in_tensor, 16, kernels=[1, 12], strides=[1, 12], name='h0'), self.is_bn))\n",
        "            h1 = lrelu(batch_norm(conv2d(h0, 16, kernels=[1, 7], strides=[1, 7], name='h1'), self.is_bn))\n",
        "            h2 = lrelu(batch_norm(conv2d(h1, 16, kernels=[3, 1], strides=[3, 1], name='h2'), self.is_bn))\n",
        "            h3 = lrelu(batch_norm(conv2d(h2, 16, kernels=[2, 1], strides=[2, 1], name='h3'), self.is_bn))\n",
        "            h4 = lrelu(batch_norm(conv2d(h3, 16, kernels=[2, 1], strides=[2, 1], name='h4'), self.is_bn))\n",
        "            h5 = lrelu(batch_norm(conv2d(h4, 16, kernels=[2, 1], strides=[2, 1], name='h5'), self.is_bn))\n",
        "            h6 = lrelu(batch_norm(conv2d(h5, 16, kernels=[2, 1], strides=[2, 1], name='h6'), self.is_bn))\n",
        "\n",
        "            return [h0, h1, h2, h3, h4, h5, h6]\n",
        "\n",
        "class BarDiscriminator(object):\n",
        "\n",
        "    def __init__(self, name='BD'):\n",
        "        self.name = name\n",
        "\n",
        "    def __call__(self, in_tensor, reuse):\n",
        "        with tf.variable_scope(self.name, reuse=reuse):\n",
        "\n",
        "            ## conv\n",
        "            h0 = lrelu(conv2d(in_tensor, 128, kernels=[1, 12], strides=[1, 12], name='h0'))\n",
        "            h1 = lrelu(conv2d(h0, 128, kernels=[1, 7], strides=[1, 7], name='h1'))\n",
        "            h2 = lrelu(conv2d(h1, 128, kernels=[2, 1], strides=[2, 1], name='h2'))\n",
        "            h3 = lrelu(conv2d(h2, 128, kernels=[2, 1], strides=[2, 1], name='h3'))\n",
        "            h4 = lrelu(conv2d(h3, 256, kernels=[4, 1], strides=[2, 1], name='h4'))\n",
        "            h5 = lrelu(conv2d(h4, 512, kernels=[3, 1], strides=[2, 1], name='h5'))\n",
        "\n",
        "            ## linear\n",
        "            h6 = tf.reshape(h5, [-1, np.product([s.value for s in h5.get_shape()[1:]])])\n",
        "            h6 = lrelu(linear(h6, 1024, name='h6'))\n",
        "            h7 = linear(h6, 1, name='h7')\n",
        "            return h5, h7\n",
        "\n",
        "class PhraseDiscriminator(object):\n",
        "    def __init__(self, name='PD'):\n",
        "        self.name = name\n",
        "\n",
        "    def __call__(self, in_tensor, reuse):\n",
        "        with tf.variable_scope(self.name, reuse=reuse):\n",
        "\n",
        "            ## conv\n",
        "            h0 = lrelu(conv2d(tf.expand_dims(in_tensor, axis=2), 512,\n",
        "                              kernels=[2, 1], strides=[1, 1], name='h0'))\n",
        "            h1 = lrelu(conv2d(h0, 128, kernels=[3, 1], strides=[3, 1],name='h1'))\n",
        "\n",
        "            ## linear\n",
        "            h2 = tf.reshape(h1, [-1, np.product([s.value for s in h1.get_shape()[1:]])])\n",
        "            h2 = lrelu(linear(h2, 1024, name='h2'))\n",
        "            h3 = linear(h2, 1, name='h3')\n",
        "        return h3\n",
        "\n",
        "\n",
        "class ImageGenerator(object):\n",
        "    def __init__(self, name='image_G', output_dim=3, is_bn=True):\n",
        "        self.output_dim = output_dim\n",
        "        self.name = name\n",
        "        self.is_bn = is_bn\n",
        "\n",
        "\n",
        "    def __call__(self, in_tensor, reuse=False):\n",
        "        with tf.variable_scope(self.name, reuse=reuse):\n",
        "\n",
        "            # linear\n",
        "            h0 = relu(batch_norm(linear(in_tensor, 128*7*7, name='h0'), self.is_bn))\n",
        "            h0 = tf.reshape(h0, [-1, 7, 7, 128])\n",
        "\n",
        "            #convnet\n",
        "            h1 = relu(batch_norm(transconv2d(h0, [14, 14], 256, kernels=[4, 4], strides=[2, 2], name='h1', padding = 'SAME'), self.is_bn))\n",
        "            h2 = relu(batch_norm(transconv2d(h1, [28, 28], self.output_dim, kernels=[4, 4], strides=[2, 2], name='h2', padding = 'SAME'), self.is_bn))\n",
        "\n",
        "        return tf.nn.tanh(h2)\n",
        "\n",
        "\n",
        "class  ImageDiscriminator(object):\n",
        "    def __init__(self, name='image_D'):\n",
        "        self.name = name\n",
        "\n",
        "    def __call__(self, in_tensor, reuse):\n",
        "        with tf.variable_scope(self.name, reuse=reuse):\n",
        "\n",
        "            ## conv\n",
        "            h0 = lrelu(batch_norm(conv2d(in_tensor, 256, kernels=[4, 4], strides=[2, 2], name='h0'), True))\n",
        "            h1 = lrelu(batch_norm(conv2d(h0, 256, kernels=[4, 4], strides=[2, 2], name='h1'), True))\n",
        "\n",
        "            ## linear\n",
        "            h1 = tf.reshape(h1, [-1, np.product([s.value for s in h1.get_shape()[1:]])])\n",
        "            h2 = lrelu(linear(h1, 1024, name='h2'))\n",
        "            h3 = linear(h2, 1, name='h3')\n",
        "\n",
        "        return h3\n",
        "\n"
      ]
    }
  ]
}