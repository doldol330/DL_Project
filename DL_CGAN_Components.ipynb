{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNMeP62ge0dIcVptH2R6Ns7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/doldol330/DL_Project/blob/main/DL_CGAN_Components.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Components"
      ],
      "metadata": {
        "id": "u-__cA5_XwfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from musegan.libs.ops import *\n",
        "from musegan.libs.utils import *\n",
        "from musegan.modules import *\n",
        "\n",
        "class Model:\n",
        "    def get_model_info(self, quiet=True):\n",
        "        num_parameter_g = np.sum([np.product([x.value for x in var.get_shape()]) for var in self.g_vars])\n",
        "        num_parameter_d = np.sum([np.product([x.value for x in var.get_shape()]) for var in self.d_vars])\n",
        "        num_parameter_all = np.sum([np.product([x.value for x in var.get_shape()]) for var in self.vars])\n",
        "\n",
        "        if not quiet:\n",
        "            print('# of parameters in G (generator)                 |', num_parameter_g)\n",
        "            print('# of parameters in D (discriminator)             |', num_parameter_d)\n",
        "            print('# of parameters in total                         |', num_parameter_all)\n",
        "\n",
        "        return num_parameter_g, num_parameter_d, num_parameter_all\n",
        "\n",
        "    def _build_optimizer(self, config):\n",
        "        # self.print_vars(self.g_vars)\n",
        "        with tf.variable_scope('Opt'):\n",
        "\n",
        "            self.d_optim = tf.train.AdamOptimizer(config.lr, beta1=config.beta1, beta2=config.beta2) \\\n",
        "                                   .minimize(self.d_loss, var_list=self.d_vars)\n",
        "\n",
        "            self.g_optim = tf.train.AdamOptimizer(config.lr, beta1=config.beta1, beta2=config.beta2) \\\n",
        "                                   .minimize(self.g_loss, var_list=self.g_vars)\n",
        "\n",
        "    def print_vars(self, var_list):\n",
        "        print('================================================')\n",
        "        for v in var_list:\n",
        "            print(v)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#######################################################################################################################\n",
        "# NowBar\n",
        "#######################################################################################################################\n",
        "\n",
        "class Nowbar(Model):\n",
        "    def _build_graph(self, config):\n",
        "        self._build_encoder(config)\n",
        "        self._build_generator(config)\n",
        "        self._build_discriminator(config)\n",
        "        self.print_vars(self.e_vars)\n",
        "        self.g_vars = self.g_vars + self.e_vars\n",
        "\n",
        "        self._build_optimizer(config)\n",
        "        self.vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=tf.get_variable_scope().name)\n",
        "\n",
        "    def _build_encoder(self, config):\n",
        "        with tf.variable_scope('E') as scope:\n",
        "            if config.acc_idx is not None:with tf.variable_scope('E') as scope:\n",
        "            # 입력 트랙을 가져옴\n",
        "            input_track = tf.slice(self.x, [0, 0, 0, config.input_idx], [-1, -1, -1, 1])\n",
        "\n",
        "            BE = BarEncoder()\n",
        "            self.nowbar = BE(input_track)  # 입력 트랙을 인코딩\n",
        "\n",
        "            self.e_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=scope.name)\n",
        "                    self.acc_track = tf.slice(self.x, [0, 0, 0, config.acc_idx], [-1, -1, -1, 1]) # take piano as condition\n",
        "                    BE = BarEncoder()\n",
        "                    self.nowbar = BE(self.acc_track)\n",
        "            else:\n",
        "                self.nowbar = None\n",
        "\n",
        "            self.e_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=scope.name)\n",
        "\n",
        "    def _build_generator(self, config):\n",
        "        with tf.variable_scope('G') as scope:\n",
        "            self.all_tracks = []\n",
        "            input_track = tf.slice(self.x, [0, 0, 0, config.input_idx], [-1, -1, -1, 1])\n",
        "            for tidx in range(4):  # 네 개의 트랙을 생성\n",
        "                with tf.variable_scope('track_{}'.format(tidx)):\n",
        "                    BG = BarGenerator(output_dim=self.output_dim)\n",
        "                    # 입력 트랙을 각 생성기에 전달\n",
        "                    tmp_track = BG(in_tensor=input_track, nowbar=self.nowbar, type_=0)\n",
        "                self.all_tracks.append(tmp_track)\n",
        "\n",
        "            self.prediction = tf.concat([t for t in self.all_tracks], 3)\n",
        "            self.prediction_binary = to_binary_tf(self.prediction)\n",
        "            self.prediction_chroma = to_chroma_tf(self.prediction_binary)\n",
        "\n",
        "            self.g_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=scope.name)\n",
        "\n",
        "            ## summary\n",
        "            prediction_image = to_image_tf(self.prediction, config.colormap)\n",
        "            self.summary_prediction_image = tf.summary.image('prediction/G', prediction_image,\n",
        "                                                             max_outputs=10)\n",
        "\n",
        "    def _build_discriminator(self, config):\n",
        "        with tf.variable_scope('D') as scope:\n",
        "\n",
        "            BD = BarDiscriminator()\n",
        "\n",
        "            self.input_real = self.x\n",
        "            self.input_fake = self.prediction\n",
        "\n",
        "            _, self.D_real = BD(self.input_real, reuse=False)\n",
        "            _, self.D_fake = BD(self.input_fake, reuse=True)\n",
        "\n",
        "            ## compute gradient panelty\n",
        "            # reshape data\n",
        "            re_real = tf.reshape(self.input_real, [-1, config.output_w * config.output_h * config.track_dim])\n",
        "            re_fake = tf.reshape(self.input_fake, [-1, config.output_w * config.output_h * config.track_dim])\n",
        "\n",
        "            # sample alpha from uniform\n",
        "            alpha = tf.random_uniform(shape=[config.batch_size, 1], minval=0., maxval=1.)\n",
        "            differences = self.input_fake - self.input_real\n",
        "            interpolates = self.input_real + (alpha * differences)\n",
        "            _, self.D_hat = BD(interpolates, reuse=True)\n",
        "\n",
        "            gradients = tf.gradients(self.D_hat, [interpolates])[0]\n",
        "            slopes = tf.sqrt(1e-8 + tf.reduce_sum(tf.square(gradients), axis=[1]))\n",
        "            gradient_penalty = tf.reduce_mean((slopes - 1.) ** 2) * config.lamda\n",
        "\n",
        "            # 손실 계산\n",
        "            self.d_loss = tf.reduce_mean(self.D_fake) - tf.reduce_mean(self.D_real) + gradient_penalty\n",
        "\n",
        "            self.d_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=scope.name)\n",
        "\n",
        "class NowbarHybrid(Nowbar):\n",
        "    def __init__(self, config):\n",
        "        with tf.variable_scope('NowbarHybrid'):\n",
        "\n",
        "            # set key vars\n",
        "            self.track_dim = config.track_dim\n",
        "            self.z_intra_dim = config.z_intra_dim\n",
        "            self.z_inter_dim = config.z_inter_dim\n",
        "            self.output_dim = config.output_dim\n",
        "\n",
        "            # placeholder\n",
        "            self.z_intra = tf.placeholder(tf.float32, shape=[None, config.z_intra_dim, config.track_dim], name='z_intra')\n",
        "            self.z_inter = tf.placeholder(tf.float32, shape=[None, config.z_inter_dim], name='z_inter')\n",
        "            self.x = tf.placeholder(tf.float32, shape=[None, config.output_w, config.output_h, config.track_dim], name='x')\n",
        "\n",
        "            # 입력 트랙 가져오기\n",
        "            input_track = tf.slice(self.x, [0, 0, 0, config.input_idx], [-1, -1, -1, 1])\n",
        "            # to list\n",
        "            self.z_final_list =  []\n",
        "\n",
        "            ffor tidx in range(4):\n",
        "                z_intra = tf.squeeze(tf.slice(self.z_intra, [0, 0, tidx], [-1, -1, 1]), squeeze_dims=2)\n",
        "                z_combined = tf.concat([z_intra, self.z_inter, tf.reshape(input_track, [-1, config.z_intra_dim])], 1)\n",
        "                self.z_final_list.append(z_combined)\n",
        "\n",
        "            self._build_graph(config)\n",
        "\n",
        "class NowbarJamming(Nowbar):\n",
        "    def __init__(self, config):\n",
        "        with tf.variable_scope('NowbarJamming'):\n",
        "\n",
        "            # set key vars\n",
        "            self.track_dim = config.track_dim\n",
        "            self.z_intra_dim = config.z_intra_dim\n",
        "            self.output_dim = config.output_dim\n",
        "\n",
        "            # placeholder\n",
        "            self.z_intra = tf.placeholder(tf.float32, shape=[None, config.z_intra_dim, config.track_dim], name='z_intra')\n",
        "            self.x = tf.placeholder(tf.float32, shape=[None, config.output_w, config.output_h, config.track_dim], name='x')\n",
        "\n",
        "            # 입력 트랙 가져오기\n",
        "            input_track = tf.slice(self.x, [0, 0, 0, config.input_idx], [-1, -1, -1, 1])\n",
        "\n",
        "            # to list\n",
        "            self.z_final_list =  []\n",
        "\n",
        "            for tidx in range(4):\n",
        "                z_intra = tf.squeeze(tf.slice(self.z_intra, [0, 0, tidx], [-1, -1, 1]), squeeze_dims=2)\n",
        "                z_combined = tf.concat([z_intra, tf.reshape(input_track, [-1, config.z_intra_dim])], 1)\n",
        "                self.z_final_list.append(z_combined)\n",
        "\n",
        "            self._build_graph(config)\n",
        "\n",
        "class NowbarComposer(Nowbar):\n",
        "    def __init__(self, config):\n",
        "        with tf.variable_scope('NowbarComposer'):\n",
        "\n",
        "            # set key vars\n",
        "            self.track_dim = config.track_dim\n",
        "            self.z_inter_dim = config.z_inter_dim\n",
        "            self.output_dim = config.output_dim\n",
        "\n",
        "            # placeholder\n",
        "            self.z_inter = tf.placeholder(tf.float32, shape=[None, config.z_inter_dim], name='z_inter')\n",
        "            self.x = tf.placeholder(tf.float32, shape=[None, config.output_w, config.output_h, self.output_dim], name='x')\n",
        "\n",
        "            # 입력 트랙 가져오기\n",
        "            input_track = tf.slice(self.x, [0, 0, 0, config.input_idx], [-1, -1, -1, 1])\n",
        "\n",
        "            # to list\n",
        "            self.z_final_list =  []\n",
        "            for tidx in range(4):\n",
        "                z_combined = tf.concat([self.z_inter, tf.reshape(input_track, [-1, config.z_inter_dim])], 1)\n",
        "                self.z_final_list.append(z_combined)\n",
        "\n",
        "            self._build_graph(config)\n",
        "\n",
        "#######################################################################################################################\n",
        "# Temporal\n",
        "#######################################################################################################################\n",
        "\n",
        "class Temporal(Model):\n",
        "    def _build_graph(self, config):\n",
        "        self._build_encoder(config)\n",
        "        self._build_bar_generator(config)\n",
        "        self._build_discriminator(config)\n",
        "\n",
        "        self.g_vars = self.g_vars + self.e_vars\n",
        "        self.print_vars(self.g_vars)\n",
        "\n",
        "        self._build_optimizer(config)\n",
        "\n",
        "        self.vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=tf.get_variable_scope().name)\n",
        "\n",
        "    def _build_encoder(self, config):\n",
        "        with tf.variable_scope('E') as scope:\n",
        "            self.nowbar_list = []\n",
        "            self.acc_track_list = []\n",
        "\n",
        "            x_tmp = tf.reshape(self.x, [-1, config.output_bar, config.output_w, config.output_h, config.track_dim])\n",
        "            BE = BarEncoder()\n",
        "\n",
        "            for bidx in range(config.output_bar):\n",
        "                acc_track = tf.slice(x_tmp, [0, bidx, 0, 0, config.acc_idx], [-1, 1, -1, -1, 1])  # 입력 트랙 선택\n",
        "                acc_track = tf.squeeze(acc_track, [1])\n",
        "                nowbar = BE(acc_track, reuse=(bidx > 0))\n",
        "                self.acc_track_list.append(acc_track)\n",
        "                self.nowbar_list.append(nowbar)\n",
        "\n",
        "            self.e_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=scope.name)\n",
        "\n",
        "    def _build_bar_generator(self, config):\n",
        "        with tf.variable_scope('G') as scope:\n",
        "            self.phrase = [[None] * 4 for _ in range(config.output_bar)]  # 네 개의 트랙 생성\n",
        "\n",
        "            for bidx in range(config.output_bar):\n",
        "                for tidx in range(4):  # 네 개의 트랙\n",
        "                    with tf.variable_scope('track_{}'.format(tidx), reuse=(bidx > 0)):\n",
        "                        BG = BarGenerator(output_dim=self.output_dim)\n",
        "                        tmp_track = BG(in_tensor=self.z_final[bidx][tidx], reuse=(bidx > 0))\n",
        "                    self.phrase[bidx][tidx] = tmp_track\n",
        "\n",
        "            self.prediction = tf.concat([tf.concat([bar for bar in track], 3) for track in self.phrase], 1)\n",
        "            self.prediction_binary = to_binary_tf(self.prediction)\n",
        "            self.prediction_chroma = to_chroma_tf(self.prediction_binary)\n",
        "\n",
        "            self.g_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=scope.name)\n",
        "\n",
        "            ## summary\n",
        "            prediction_image = to_image_tf(self.prediction, config.colormap)\n",
        "            self.summary_prediction_image = tf.summary.image('prediction/G', prediction_image,\n",
        "                                                             max_outputs=10)\n",
        "    def _build_discriminator(self, config):\n",
        "        with tf.variable_scope('D') as scope:\n",
        "\n",
        "            BD = BarDiscriminator()\n",
        "            PD = PhraseDiscriminator()\n",
        "\n",
        "            # real & fake\n",
        "            self.input_real = tf.reshape(self.x, [-1, config.output_w, config.output_h, config.track_dim])\n",
        "            self.input_fake = tf.reshape(self.prediction, [-1, config.output_w, config.output_h, config.track_dim])\n",
        "\n",
        "            self.D_real_h5, _ = BD(self.input_real, reuse=False)\n",
        "            self.D_fake_h5, _ = BD(self.input_fake, reuse=True)\n",
        "\n",
        "\n",
        "            self.D_real_h5_r = tf.reshape(self.D_real_h5, [-1, config.output_bar, 128])\n",
        "            self.D_fake_h5_r = tf.reshape(self.D_fake_h5, [-1, config.output_bar, 128])\n",
        "\n",
        "            self.D_real = PD(self.D_real_h5_r, reuse=False)\n",
        "            self.D_fake = PD(self.D_fake_h5_r, reuse=True)\n",
        "\n",
        "            ## compute gradient panelty\n",
        "            # reshape data\n",
        "            re_real = tf.reshape(self.input_real, [-1, config.output_bar * config.output_w * config.output_h * config.track_dim])\n",
        "            re_fake = tf.reshape(self.input_fake, [-1, config.output_bar * config.output_w * config.output_h * config.track_dim])\n",
        "\n",
        "            # sample alpha from uniform\n",
        "            print(re_real.get_shape()[0])\n",
        "            alpha = tf.random_uniform(\n",
        "                                shape=[config.batch_size,1],\n",
        "                                minval=0.,\n",
        "                                maxval=1.)\n",
        "\n",
        "            differences = re_fake - re_real\n",
        "            interpolates = re_real + (alpha*differences)\n",
        "\n",
        "            # feed interpolate into D\n",
        "            X_hat = tf.reshape(interpolates, [-1, config.output_w, config.output_h, config.track_dim])\n",
        "            self.D_hat_h5, _ = BD(X_hat, reuse=True)\n",
        "            self.D_hat_h5_r  = tf.reshape(self.D_hat_h5, [-1, config.output_bar, 128])\n",
        "            self.D_hat = PD(self.D_hat_h5_r, reuse=True)\n",
        "\n",
        "            # compute gradients panelty\n",
        "            gradients = tf.gradients(self.D_hat, [interpolates])[0]\n",
        "            slopes = tf.sqrt(1e-8 + tf.reduce_sum(tf.square(gradients), reduction_indices=[1]))\n",
        "            gradient_penalty = tf.reduce_mean((slopes-1.)**2) * config.lamda\n",
        "\n",
        "            #loss\n",
        "            self.d_loss = tf.reduce_mean(self.D_fake) - tf.reduce_mean(self.D_real)\n",
        "            self.g_loss = -tf.reduce_mean(self.D_fake)\n",
        "            self.d_loss += gradient_penalty\n",
        "\n",
        "            self.d_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=scope.name)\n",
        "\n",
        "class TemporalHybrid(Temporal):\n",
        "    def __init__(self, config):\n",
        "        with tf.variable_scope('TemporalHybrid'):\n",
        "\n",
        "            # set key vars\n",
        "            self.track_dim = config.track_dim\n",
        "            self.z_intra_dim = config.z_intra_dim\n",
        "            self.z_inter_dim = config.z_inter_dim\n",
        "            self.output_dim = config.output_dim\n",
        "\n",
        "            # placeholder\n",
        "            self.z_intra_v = tf.placeholder(tf.float32, shape=[None, config.z_intra_dim, config.track_dim],\n",
        "                 name='z_intra_v') # input_latent_i_t\n",
        "            self.z_intra_i = tf.placeholder(tf.float32, shape=[None, config.z_intra_dim, config.track_dim],\n",
        "                name='z_intra_i') # input_latent_i\n",
        "            self.z_inter_v = tf.placeholder(tf.float32, shape=[None, config.z_inter_dim]\n",
        "                , name='z_inter_v')  # input_latent_t\n",
        "            self.z_inter_i = tf.placeholder(tf.float32, shape=[None, config.z_inter_dim]\n",
        "                , name='z_inter_i')  # input_latent\n",
        "\n",
        "            self.x = tf.placeholder(tf.float32, shape=[None, config.output_w*config.output_bar, config.output_h, config.track_dim], name='x')\n",
        "\n",
        "            self._build_phrase_generator(config)\n",
        "\n",
        "            # to list\n",
        "            self.z_final = [[None]*config.track_dim for _ in range(config.output_bar)]\n",
        "\n",
        "            for bidx in range(config.output_bar):\n",
        "                for tidx in range(config.track_dim):\n",
        "\n",
        "                    tz_inter_v = tf.squeeze(tf.slice(self.z_inter_v_hat, [0, 0, bidx], [-1, -1, 1]), axis=2)\n",
        "                    tz_intra_v = tf.squeeze(tf.slice(self.z_intra_v_hat[tidx], [0, 0, bidx], [-1, -1, 1]), axis=2)\n",
        "                    tz_inter_i = self.z_inter_i\n",
        "                    tz_intra_i = tf.squeeze(tf.slice(self.z_intra_i, [0, 0, tidx], [-1, -1, 1]), axis=2)\n",
        "\n",
        "                    self.z_final[bidx][tidx] = tf.concat([tz_inter_v, tz_intra_v, tz_inter_i, tz_intra_i], 1)\n",
        "\n",
        "            self._build_graph(config)\n",
        "\n",
        "    def _build_phrase_generator(self, config):\n",
        "        with tf.variable_scope('G') as scope:\n",
        "            PG = PhraseGenerator(output_dim=config.z_inter_dim)\n",
        "\n",
        "            # arrange time variant latents\n",
        "            self.z_inter_v_hat = PG(self.z_inter_v, reuse=False)\n",
        "            self.z_intra_v_hat = []\n",
        "            for tidx in range(config.track_dim):\n",
        "                tz_intra_v = tf.squeeze(tf.slice(self.z_intra_v, [0, 0, tidx], [-1, -1, 1]), squeeze_dims=2)\n",
        "                tz_intra_v_hat = PG(tz_intra_v, reuse=True)\n",
        "                self.z_intra_v_hat.append(tz_intra_v_hat)\n",
        "\n",
        "\n",
        "class TemporalJamming(Temporal):\n",
        "    def __init__(self, config):\n",
        "        with tf.variable_scope('TemporalJamming'):\n",
        "            # set key vars\n",
        "            self.track_dim = config.track_dim\n",
        "            self.z_intra_dim = config.z_intra_dim\n",
        "            self.output_dim = config.output_dim\n",
        "\n",
        "            # placeholder\n",
        "            self.z_intra_v = tf.placeholder(tf.float32, shape=[None, config.z_intra_dim, config.track_dim], name='z_intra_v')\n",
        "            self.x = tf.placeholder(tf.float32, shape=[None, config.output_w*config.output_bar, config.output_h, config.track_dim], name='x')\n",
        "\n",
        "            input_track = tf.slice(self.x, [0, 0, 0, config.input_idx], [-1, -1, -1, 1])\n",
        "\n",
        "            self._build_phrase_generator(config)\n",
        "\n",
        "            # to list\n",
        "            self.z_final = [[None] * 4 for _ in range(config.output_bar)]\n",
        "\n",
        "            for bidx in range(config.output_bar):\n",
        "                for tidx in range(4):\n",
        "                    tz_intra_v = tf.squeeze(tf.slice(self.z_intra_v, [0, 0, tidx], [-1, -1, 1]), squeeze_dims=2)\n",
        "                    tz_combined = tf.concat([tz_intra_v, tf.reshape(input_track, [-1, config.z_intra_dim])], 1)\n",
        "                    self.z_final[bidx][tidx] = tz_combined\n",
        "\n",
        "            self._build_graph(config)\n",
        "\n",
        "\n",
        "    def _build_phrase_generator(self, config):\n",
        "        with tf.variable_scope('G') as scope:\n",
        "            PG = PhraseGenerator(output_dim=config.z_intra_dim)\n",
        "\n",
        "            # 입력 트랙 정보를 가져옵니다.\n",
        "            input_track = tf.slice(self.x, [0, 0, 0, config.input_idx], [-1, -1, -1, 1])\n",
        "            input_track_reshaped = tf.reshape(input_track, [-1, config.z_intra_dim])\n",
        "\n",
        "            self.z_intra_v_hat = []\n",
        "\n",
        "            for tidx in range(4):  # 네 개의 트랙\n",
        "                # 각 트랙에 대한 노이즈 벡터와 입력 트랙 정보를 결합\n",
        "                tz_intra_v = tf.squeeze(tf.slice(self.z_intra_v, [0, 0, tidx], [-1, -1, 1]), squeeze_dims=2)\n",
        "                tz_combined = tf.concat([tz_intra_v, input_track_reshaped], 1)\n",
        "\n",
        "                # 결합된 벡터를 사용하여 시간변화 노이즈 벡터 생성\n",
        "                tz_intra_v_hat = PG(tz_combined, reuse=tidx > 0)\n",
        "                self.z_intra_v_hat.append(tz_intra_v_hat)\n",
        "\n",
        "\n",
        "class TemporalComposer(Temporal):\n",
        "    def __init__(self, config):\n",
        "        with tf.variable_scope('TemporalComposer'):\n",
        "            # set key vars\n",
        "            self.track_dim = config.track_dim\n",
        "            self.z_inter_dim = config.z_inter_dim\n",
        "            self.output_dim = config.output_dim\n",
        "\n",
        "            # placeholder\n",
        "            self.z_inter_v = tf.placeholder(tf.float32, shape=[None, config.z_inter_dim], name='z_inter_v')\n",
        "            self.x = tf.placeholder(tf.float32, shape=[None, config.output_w*config.output_bar, config.output_h, config.track_dim], name='x')\n",
        "\n",
        "            input_track = tf.slice(self.x, [0, 0, 0, config.input_idx], [-1, -1, -1, 1])\n",
        "\n",
        "            self._build_phrase_generator(config)\n",
        "\n",
        "            # to list\n",
        "            self.z_final = [[None] * 4 for _ in range(config.output_bar)]\n",
        "\n",
        "            for bidx in range(config.output_bar):\n",
        "                for tidx in range(4):\n",
        "                    tz_combined = tf.concat([self.z_inter_v, tf.reshape(input_track, [-1, config.z_inter_dim])], 1)\n",
        "                    self.z_final[bidx][tidx] = tz_combined\n",
        "\n",
        "            self._build_graph(config)\n",
        "\n",
        "\n",
        "    def _build_phrase_generator(self, config):\n",
        "        with tf.variable_scope('G') as scope:\n",
        "            PG = PhraseGenerator(output_dim=config.z_inter_dim)\n",
        "\n",
        "            # 입력 트랙 정보를 가져옵니다.\n",
        "            input_track = tf.slice(self.x, [0, 0, 0, config.input_idx], [-1, -1, -1, 1])\n",
        "            input_track_reshaped = tf.reshape(input_track, [-1, config.z_inter_dim])\n",
        "\n",
        "            self.z_inter_v_hat = []\n",
        "\n",
        "            for bidx in range(config.output_bar):\n",
        "                # 각 막대에 대한 노이즈 벡터와 입력 트랙 정보를 결합\n",
        "                tz_inter_v = tf.squeeze(tf.slice(self.z_inter_v, [0, 0, bidx], [-1, -1, 1]), axis=2)\n",
        "                tz_combined = tf.concat([tz_inter_v, input_track_reshaped], 1)\n",
        "\n",
        "                # 결합된 벡터를 사용하여 시간변화 노이즈 벡터 생성\n",
        "                tz_inter_v_hat = PG(tz_combined, reuse=bidx > 0)\n",
        "                self.z_inter_v_hat.append(tz_inter_v_hat)\n",
        "\n",
        "\n",
        "#######################################################################################################################\n",
        "# RNN\n",
        "#######################################################################################################################\n",
        "\n",
        "class RNNComposer(Temporal):\n",
        "    def __init__(self, config):\n",
        "        with tf.variable_scope('RNNComposer'):\n",
        "\n",
        "            # set key vars\n",
        "            self.track_dim = config.track_dim\n",
        "            self.z_inter_dim = config.z_inter_dim\n",
        "            self.output_dim = config.output_dim\n",
        "            self.output_bar = config.output_bar\n",
        "\n",
        "            input_track = tf.slice(self.x, [0, 0, 0, config.input_idx], [-1, -1, -1, 1])\n",
        "            input_track_reshaped = tf.reshape(input_track, [config.batch_size, config.output_bar, config.z_inter_dim])\n",
        "\n",
        "            # placeholder\n",
        "            self.z_inter = tf.placeholder(tf.float32, shape=[config.batch_size, config.output_bar, config.z_inter_dim], name='z_inter')\n",
        "            self.x = tf.placeholder(tf.float32, shape=[None, config.output_w*config.output_bar, config.output_h, self.output_dim], name='x')\n",
        "\n",
        "            self.z_final = [[None]*config.track_dim for _ in range(config.output_bar)]\n",
        "            # LSTM에 입력 트랙 정보 추가\n",
        "            self.z_inter_combined = tf.concat([self.z_inter, input_track_reshaped], axis=2)\n",
        "            self._build_phrase_generator_rnn(config)\n",
        "\n",
        "            for bidx in range(config.output_bar):\n",
        "                for tidx in range(config.track_dim):\n",
        "                    tz_inter = tf.squeeze(tf.slice(self.z_inter_v_hat, [0, bidx, 0], [-1, 1, -1]), axis=1)\n",
        "                    print(tz_inter.get_shape()) # (128, 4, 128)\n",
        "                    self.z_final[bidx][tidx] = tz_inter\n",
        "\n",
        "            self._build_graph(config)\n",
        "\n",
        "\n",
        "    def _build_phrase_generator_rnn(self, config):\n",
        "        with tf.variable_scope('G') as scope:\n",
        "            self.cell = tf.contrib.rnn.LSTMBlockCell(config.state_size)\n",
        "            self.initial_state = self.cell.zero_state(config.batch_size, tf.float32)\n",
        "            self.z_inter_v_hat, last_state = tf.nn.dynamic_rnn(self.cell, self.z_inter, initial_state=self.initial_state)\n",
        "            print(self.z_inter_v_hat.get_shape()) # (128, 4, 128)\n",
        "\n",
        "            self.r_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=scope.name)\n",
        "            print(self.r_vars)\n",
        "\n",
        "#######################################################################################################################\n",
        "# GAN\n",
        "#######################################################################################################################\n",
        "\n",
        "class ImageMNIST(Model):\n",
        "    def __init__(self, config):\n",
        "        with tf.variable_scope('NowbarComposer'):\n",
        "\n",
        "            self.z_dim = config.z_dim\n",
        "            self.output_dim = config.output_dim\n",
        "\n",
        "            # placeholder\n",
        "            self.z = tf.placeholder(tf.float32, shape=[None, config.z_dim], name='z_inter')\n",
        "            self.x = tf.placeholder(tf.float32, shape=[None, config.output_w, config.output_h, self.output_dim], name='x')\n",
        "\n",
        "            self._build_graph(config)\n",
        "\n",
        "    def _build_graph(self, config):\n",
        "        self._build_generator(config)\n",
        "        self._build_discriminator(config)\n",
        "        self._build_optimizer(config)\n",
        "\n",
        "        self.vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=tf.get_variable_scope().name)\n",
        "\n",
        "    def _build_generator(self, config):\n",
        "        with tf.variable_scope('G') as scope:\n",
        "            G = ImageGenerator(output_dim=self.output_dim)\n",
        "            self.prediction = G(in_tensor=self.z)\n",
        "            # print(self.prediction.get_shape())\n",
        "\n",
        "            self.g_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=scope.name)\n",
        "\n",
        "            ## summary\n",
        "            prediction_image = to_image_tf(self.prediction, config.colormap)\n",
        "            self.summary_prediction_image = tf.summary.image('prediction/G', prediction_image,\n",
        "                                                             max_outputs=10)\n",
        "\n",
        "    def _build_discriminator(self, config):\n",
        "        with tf.variable_scope('D') as scope:\n",
        "\n",
        "            D = ImageDiscriminator()\n",
        "\n",
        "            self.input_real = self.x\n",
        "            self.input_fake = self.prediction\n",
        "\n",
        "            self.D_real = D(self.input_real, reuse=False)\n",
        "            self.D_fake = D(self.input_fake, reuse=True)\n",
        "\n",
        "            epsilon = tf.random_uniform([], 0.0, 1.0)\n",
        "\n",
        "            X_hat = epsilon * self.input_real + (1 - epsilon) * self.input_fake\n",
        "            D_hat = D(X_hat, reuse=True)\n",
        "\n",
        "            self.d_loss = tf.reduce_mean(self.D_fake) - tf.reduce_mean(self.D_real)\n",
        "            self.g_loss = tf.reduce_mean(self.D_fake)\n",
        "\n",
        "            gp = tf.gradients(D_hat, X_hat)[0]\n",
        "            gp = tf.sqrt(tf.reduce_sum(tf.square(gp), axis=1))\n",
        "            gp = tf.reduce_mean(tf.square(gp - 1.0) * config.lamda)\n",
        "\n",
        "            self.d_loss += gp\n",
        "            self.d_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=scope.name)\n"
      ],
      "metadata": {
        "id": "bx083gsUCp3E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}